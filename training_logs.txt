Loaded config from: configs/prod/mps_optimized.json
CLI overrides: {'resume': False, 'debug': False}
============================================================
RL TOKEN COMPRESSION - JOINT TRAINING
============================================================
data_path: data/processed/processed_data.json
output_dir: results/mps_training
batch_size: 16
max_epochs: 100
device: mps

Using device: mps
2025-08-10 02:18:35,472 - src.training.trainer - INFO - Checkpoint manager initialized: results/mps_training
INFO:src.training.trainer:Checkpoint manager initialized: results/mps_training
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
2025-08-10 02:18:36,329 - src.training.trainer - INFO - Loaded 40000 sequences from data/processed/processed_data.json
INFO:src.training.trainer:Loaded 40000 sequences from data/processed/processed_data.json
2025-08-10 02:18:36,395 - src.training.trainer - INFO - Loaded 5000 sequences from data/processed/val_data.json
INFO:src.training.trainer:Loaded 5000 sequences from data/processed/val_data.json
INFO:src.training.rewards:Initialized information-theoretic reward with adaptive temperature
INFO:src.utils.apple_silicon_memory:  MPS backend built with unified memory support
INFO:src.utils.apple_silicon_memory:UnifiedMemoryManager initialized for Apple Silicon
INFO:src.utils.apple_silicon_memory:  Total unified memory: 48.0GB
INFO:src.utils.apple_silicon_memory:  Target memory usage: 32.0GB (66.7%)
INFO:src.utils.apple_silicon_memory:  Device: mps
INFO:src.utils.apple_silicon_memory:  MPS backend available and optimized
INFO:src.utils.apple_silicon_memory:Apple Silicon optimizations configured
INFO:src.utils.apple_silicon_memory:  Unified memory optimizations: enabled
INFO:src.utils.apple_silicon_memory:  MPS high watermark: 80% (unified memory)
INFO:src.utils.apple_silicon_memory:  MPS low watermark: 60% (cleanup threshold)
INFO:src.utils.apple_silicon_memory:  Threading optimized for M4 Pro (8 performance cores)
2025-08-10 02:18:36,545 - src.training.trainer - INFO - Joint trainer initialized successfully - Policy: 865,281 params, Reconstructor: 124,440,576 params, Train: 40000 seqs, Val: 5000 seqs, Device: mps, Batch: 16
INFO:src.training.trainer:Joint trainer initialized successfully - Policy: 865,281 params, Reconstructor: 124,440,576 params, Train: 40000 seqs, Val: 5000 seqs, Device: mps, Batch: 16
Starting joint training...
2025-08-10 02:18:36,545 - src.utils.logging - INFO - Starting experiment: joint_training
INFO:src.utils.logging:Starting experiment: joint_training
2025-08-10 02:18:36,545 - src.training.trainer - INFO - Starting joint training session 'joint_training' - Epochs: 100, Output: results/mps_training, Total params: 125,305,857
INFO:src.training.trainer:Starting joint training session 'joint_training' - Epochs: 100, Output: results/mps_training, Total params: 125,305,857
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
2025-08-10 02:18:42,378 - src.utils.metrics - INFO - Step 1, Epoch 0: {'policy_loss': -0.04258709418354556, 'reconstructor_loss': 4.082834154367447, 'total_loss': 4.040246963500977, 'reward_mean': 0.0004853906762036786, 'compression_ratio': 0.6210852861404419, 'temperature': 1.0, 'mask_ratio': 0.45306264981627464, 'policy_grad_norm': 0.006123475894355579, 'reconstructor_grad_norm': 1.5837094262242317}
INFO:src.utils.metrics:Step 1, Epoch 0: {'policy_loss': -0.04258709418354556, 'reconstructor_loss': 4.082834154367447, 'total_loss': 4.040246963500977, 'reward_mean': 0.0004853906762036786, 'compression_ratio': 0.6210852861404419, 'temperature': 1.0, 'mask_ratio': 0.45306264981627464, 'policy_grad_norm': 0.006123475894355579, 'reconstructor_grad_norm': 1.5837094262242317}
2025-08-10 02:18:47,188 - src.utils.metrics - INFO - Step 2, Epoch 0: {'policy_loss': -0.013223535032011569, 'reconstructor_loss': 3.579421728849411, 'total_loss': 3.566198229789734, 'reward_mean': 0.0006085971781430999, 'compression_ratio': 0.6524882391095161, 'temperature': 0.99991, 'mask_ratio': 0.41923507675528526, 'policy_grad_norm': 0.0007378355694527272, 'reconstructor_grad_norm': 0.8915322385728359}
INFO:src.utils.metrics:Step 2, Epoch 0: {'policy_loss': -0.013223535032011569, 'reconstructor_loss': 3.579421728849411, 'total_loss': 3.566198229789734, 'reward_mean': 0.0006085971781430999, 'compression_ratio': 0.6524882391095161, 'temperature': 0.99991, 'mask_ratio': 0.41923507675528526, 'policy_grad_norm': 0.0007378355694527272, 'reconstructor_grad_norm': 0.8915322385728359}
2025-08-10 02:18:52,655 - src.utils.metrics - INFO - Step 3, Epoch 0: {'policy_loss': -0.030258203856647015, 'reconstructor_loss': 3.5760744214057922, 'total_loss': 3.54581618309021, 'reward_mean': 0.000823116478841257, 'compression_ratio': 0.6670415699481964, 'temperature': 0.99982, 'mask_ratio': 0.41000940650701523, 'policy_grad_norm': 0.000571834942093119, 'reconstructor_grad_norm': 0.8814166318625212}
INFO:src.utils.metrics:Step 3, Epoch 0: {'policy_loss': -0.030258203856647015, 'reconstructor_loss': 3.5760744214057922, 'total_loss': 3.54581618309021, 'reward_mean': 0.000823116478841257, 'compression_ratio': 0.6670415699481964, 'temperature': 0.99982, 'mask_ratio': 0.41000940650701523, 'policy_grad_norm': 0.000571834942093119, 'reconstructor_grad_norm': 0.8814166318625212}
2025-08-10 02:18:59,013 - src.utils.metrics - INFO - Step 4, Epoch 0: {'policy_loss': -0.07614602404646575, 'reconstructor_loss': 3.986079692840576, 'total_loss': 3.9099337458610535, 'reward_mean': 0.0008531747844244819, 'compression_ratio': 0.6241006031632423, 'temperature': 0.99973, 'mask_ratio': 0.45289700850844383, 'policy_grad_norm': 0.0017680604178167414, 'reconstructor_grad_norm': 1.136934332549572}
INFO:src.utils.metrics:Step 4, Epoch 0: {'policy_loss': -0.07614602404646575, 'reconstructor_loss': 3.986079692840576, 'total_loss': 3.9099337458610535, 'reward_mean': 0.0008531747844244819, 'compression_ratio': 0.6241006031632423, 'temperature': 0.99973, 'mask_ratio': 0.45289700850844383, 'policy_grad_norm': 0.0017680604178167414, 'reconstructor_grad_norm': 1.136934332549572}
2025-08-10 02:19:03,887 - src.utils.metrics - INFO - Step 5, Epoch 0: {'policy_loss': -0.031635050021577626, 'reconstructor_loss': 3.329550087451935, 'total_loss': 3.2979151010513306, 'reward_mean': 0.00111218720121542, 'compression_ratio': 0.6784434840083122, 'temperature': 0.9996400000000001, 'mask_ratio': 0.39270104095339775, 'policy_grad_norm': 0.0022544928824572708, 'reconstructor_grad_norm': 0.7882799841463566}
INFO:src.utils.metrics:Step 5, Epoch 0: {'policy_loss': -0.031635050021577626, 'reconstructor_loss': 3.329550087451935, 'total_loss': 3.2979151010513306, 'reward_mean': 0.00111218720121542, 'compression_ratio': 0.6784434840083122, 'temperature': 0.9996400000000001, 'mask_ratio': 0.39270104095339775, 'policy_grad_norm': 0.0022544928824572708, 'reconstructor_grad_norm': 0.7882799841463566}
2025-08-10 02:19:10,103 - src.utils.metrics - INFO - Step 6, Epoch 0: {'policy_loss': -0.059735462069511414, 'reconstructor_loss': 3.678485184907913, 'total_loss': 3.6187497675418854, 'reward_mean': 0.0013755038164617872, 'compression_ratio': 0.6472558900713921, 'temperature': 0.99955, 'mask_ratio': 0.4235512278974056, 'policy_grad_norm': 0.0015311550928345241, 'reconstructor_grad_norm': 0.9697014298290014}
INFO:src.utils.metrics:Step 6, Epoch 0: {'policy_loss': -0.059735462069511414, 'reconstructor_loss': 3.678485184907913, 'total_loss': 3.6187497675418854, 'reward_mean': 0.0013755038164617872, 'compression_ratio': 0.6472558900713921, 'temperature': 0.99955, 'mask_ratio': 0.4235512278974056, 'policy_grad_norm': 0.0015311550928345241, 'reconstructor_grad_norm': 0.9697014298290014}
2025-08-10 02:19:16,658 - src.utils.metrics - INFO - Step 7, Epoch 0: {'policy_loss': -0.013860599894542247, 'reconstructor_loss': 3.903065323829651, 'total_loss': 3.8892047703266144, 'reward_mean': 0.0004678938419147016, 'compression_ratio': 0.6508506089448929, 'temperature': 0.9994599999999999, 'mask_ratio': 0.4240994565188885, 'policy_grad_norm': 0.00029724098567385226, 'reconstructor_grad_norm': 1.198488973081112}
INFO:src.utils.metrics:Step 7, Epoch 0: {'policy_loss': -0.013860599894542247, 'reconstructor_loss': 3.903065323829651, 'total_loss': 3.8892047703266144, 'reward_mean': 0.0004678938419147016, 'compression_ratio': 0.6508506089448929, 'temperature': 0.9994599999999999, 'mask_ratio': 0.4240994565188885, 'policy_grad_norm': 0.00029724098567385226, 'reconstructor_grad_norm': 1.198488973081112}
2025-08-10 02:19:23,998 - src.utils.metrics - INFO - Step 8, Epoch 0: {'policy_loss': -0.023192583408672363, 'reconstructor_loss': 4.191812753677368, 'total_loss': 4.16862016916275, 'reward_mean': 0.0005102232188392009, 'compression_ratio': 0.6295685321092606, 'temperature': 0.99937, 'mask_ratio': 0.4508049339056015, 'policy_grad_norm': 0.0005973385023025912, 'reconstructor_grad_norm': 1.0870059356093407}
INFO:src.utils.metrics:Step 8, Epoch 0: {'policy_loss': -0.023192583408672363, 'reconstructor_loss': 4.191812753677368, 'total_loss': 4.16862016916275, 'reward_mean': 0.0005102232188392009, 'compression_ratio': 0.6295685321092606, 'temperature': 0.99937, 'mask_ratio': 0.4508049339056015, 'policy_grad_norm': 0.0005973385023025912, 'reconstructor_grad_norm': 1.0870059356093407}
2025-08-10 02:19:31,620 - src.utils.metrics - INFO - Step 9, Epoch 0: {'policy_loss': -0.034697444760240614, 'reconstructor_loss': 3.98786523938179, 'total_loss': 3.953167736530304, 'reward_mean': 0.0006199803274284932, 'compression_ratio': 0.6339042335748672, 'temperature': 0.99928, 'mask_ratio': 0.4552890844643116, 'policy_grad_norm': 0.0008136551477946341, 'reconstructor_grad_norm': 0.7019200781360269}
INFO:src.utils.metrics:Step 9, Epoch 0: {'policy_loss': -0.034697444760240614, 'reconstructor_loss': 3.98786523938179, 'total_loss': 3.953167736530304, 'reward_mean': 0.0006199803274284932, 'compression_ratio': 0.6339042335748672, 'temperature': 0.99928, 'mask_ratio': 0.4552890844643116, 'policy_grad_norm': 0.0008136551477946341, 'reconstructor_grad_norm': 0.7019200781360269}
2025-08-10 02:19:39,740 - src.utils.metrics - INFO - Step 10, Epoch 0: {'policy_loss': -0.027898384490981698, 'reconstructor_loss': 3.8146658837795258, 'total_loss': 3.7867675125598907, 'reward_mean': 0.0004442306726559764, 'compression_ratio': 0.6726848259568214, 'temperature': 0.99919, 'mask_ratio': 0.4041324332356453, 'policy_grad_norm': 0.0011611635691224365, 'reconstructor_grad_norm': 1.4966336786746979}
INFO:src.utils.metrics:Step 10, Epoch 0: {'policy_loss': -0.027898384490981698, 'reconstructor_loss': 3.8146658837795258, 'total_loss': 3.7867675125598907, 'reward_mean': 0.0004442306726559764, 'compression_ratio': 0.6726848259568214, 'temperature': 0.99919, 'mask_ratio': 0.4041324332356453, 'policy_grad_norm': 0.0011611635691224365, 'reconstructor_grad_norm': 1.4966336786746979}
2025-08-10 02:19:46,893 - src.utils.metrics - INFO - Step 11, Epoch 0: {'policy_loss': -0.02960701141273603, 'reconstructor_loss': 3.6193114817142487, 'total_loss': 3.589704394340515, 'reward_mean': 0.0010475537837919546, 'compression_ratio': 0.670168325304985, 'temperature': 0.9991, 'mask_ratio': 0.3996349759399891, 'policy_grad_norm': 0.0014920604226063006, 'reconstructor_grad_norm': 1.0619794838130474}
INFO:src.utils.metrics:Step 11, Epoch 0: {'policy_loss': -0.02960701141273603, 'reconstructor_loss': 3.6193114817142487, 'total_loss': 3.589704394340515, 'reward_mean': 0.0010475537837919546, 'compression_ratio': 0.670168325304985, 'temperature': 0.9991, 'mask_ratio': 0.3996349759399891, 'policy_grad_norm': 0.0014920604226063006, 'reconstructor_grad_norm': 1.0619794838130474}
2025-08-10 02:19:53,640 - src.utils.metrics - INFO - Step 12, Epoch 0: {'policy_loss': -0.029711700975894928, 'reconstructor_loss': 3.9076091647148132, 'total_loss': 3.877897471189499, 'reward_mean': 0.00046857264146638045, 'compression_ratio': 0.66050636023283, 'temperature': 0.9990100000000001, 'mask_ratio': 0.41944779828190804, 'policy_grad_norm': 0.00072365178129985, 'reconstructor_grad_norm': 1.0432140808552504}
INFO:src.utils.metrics:Step 12, Epoch 0: {'policy_loss': -0.029711700975894928, 'reconstructor_loss': 3.9076091647148132, 'total_loss': 3.877897471189499, 'reward_mean': 0.00046857264146638045, 'compression_ratio': 0.66050636023283, 'temperature': 0.9990100000000001, 'mask_ratio': 0.41944779828190804, 'policy_grad_norm': 0.00072365178129985, 'reconstructor_grad_norm': 1.0432140808552504}
2025-08-10 02:20:01,708 - src.utils.metrics - INFO - Step 13, Epoch 0: {'policy_loss': -0.007951951934956014, 'reconstructor_loss': 4.634135335683823, 'total_loss': 4.626183450222015, 'reward_mean': 0.00015192235390770747, 'compression_ratio': 0.6081090644001961, 'temperature': 0.99892, 'mask_ratio': 0.4757016748189926, 'policy_grad_norm': 0.0005347858468667255, 'reconstructor_grad_norm': 1.1988902315497398}
INFO:src.utils.metrics:Step 13, Epoch 0: {'policy_loss': -0.007951951934956014, 'reconstructor_loss': 4.634135335683823, 'total_loss': 4.626183450222015, 'reward_mean': 0.00015192235390770747, 'compression_ratio': 0.6081090644001961, 'temperature': 0.99892, 'mask_ratio': 0.4757016748189926, 'policy_grad_norm': 0.0005347858468667255, 'reconstructor_grad_norm': 1.1988902315497398}
2025-08-10 02:20:09,487 - src.utils.metrics - INFO - Step 14, Epoch 0: {'policy_loss': -0.030900489713530988, 'reconstructor_loss': 3.55268257856369, 'total_loss': 3.521782100200653, 'reward_mean': 0.0010059132671358384, 'compression_ratio': 0.6597215309739113, 'temperature': 0.99883, 'mask_ratio': 0.4162716306746006, 'policy_grad_norm': 0.00045550675531558227, 'reconstructor_grad_norm': 0.7698364574462175}
INFO:src.utils.metrics:Step 14, Epoch 0: {'policy_loss': -0.030900489713530988, 'reconstructor_loss': 3.55268257856369, 'total_loss': 3.521782100200653, 'reward_mean': 0.0010059132671358384, 'compression_ratio': 0.6597215309739113, 'temperature': 0.99883, 'mask_ratio': 0.4162716306746006, 'policy_grad_norm': 0.00045550675531558227, 'reconstructor_grad_norm': 0.7698364574462175}
2025-08-10 02:20:18,505 - src.utils.metrics - INFO - Step 15, Epoch 0: {'policy_loss': -0.009705437056254596, 'reconstructor_loss': 4.078513741493225, 'total_loss': 4.068808317184448, 'reward_mean': 0.0003293133839861184, 'compression_ratio': 0.6236804276704788, 'temperature': 0.9987400000000001, 'mask_ratio': 0.45697931945323944, 'policy_grad_norm': 0.00041680374306451995, 'reconstructor_grad_norm': 0.9820341318845749}
INFO:src.utils.metrics:Step 15, Epoch 0: {'policy_loss': -0.009705437056254596, 'reconstructor_loss': 4.078513741493225, 'total_loss': 4.068808317184448, 'reward_mean': 0.0003293133839861184, 'compression_ratio': 0.6236804276704788, 'temperature': 0.9987400000000001, 'mask_ratio': 0.45697931945323944, 'policy_grad_norm': 0.00041680374306451995, 'reconstructor_grad_norm': 0.9820341318845749}
2025-08-10 02:20:29,083 - src.utils.metrics - INFO - Step 16, Epoch 0: {'policy_loss': -0.030082604382187128, 'reconstructor_loss': 3.852750390768051, 'total_loss': 3.822667747735977, 'reward_mean': 0.0010648836000655137, 'compression_ratio': 0.6424217969179153, 'temperature': 0.99865, 'mask_ratio': 0.4390799254179001, 'policy_grad_norm': 0.0022705115120515984, 'reconstructor_grad_norm': 0.9041860029101372}
INFO:src.utils.metrics:Step 16, Epoch 0: {'policy_loss': -0.030082604382187128, 'reconstructor_loss': 3.852750390768051, 'total_loss': 3.822667747735977, 'reward_mean': 0.0010648836000655137, 'compression_ratio': 0.6424217969179153, 'temperature': 0.99865, 'mask_ratio': 0.4390799254179001, 'policy_grad_norm': 0.0022705115120515984, 'reconstructor_grad_norm': 0.9041860029101372}
2025-08-10 02:20:40,454 - src.utils.metrics - INFO - Step 17, Epoch 0: {'policy_loss': -0.02653601684141904, 'reconstructor_loss': 4.058435350656509, 'total_loss': 4.031899392604828, 'reward_mean': 0.0004536959900178772, 'compression_ratio': 0.628704346716404, 'temperature': 0.99856, 'mask_ratio': 0.44887303560972214, 'policy_grad_norm': 0.0006609903316530108, 'reconstructor_grad_norm': 0.9894334822893143}
INFO:src.utils.metrics:Step 17, Epoch 0: {'policy_loss': -0.02653601684141904, 'reconstructor_loss': 4.058435350656509, 'total_loss': 4.031899392604828, 'reward_mean': 0.0004536959900178772, 'compression_ratio': 0.628704346716404, 'temperature': 0.99856, 'mask_ratio': 0.44887303560972214, 'policy_grad_norm': 0.0006609903316530108, 'reconstructor_grad_norm': 0.9894334822893143}
2025-08-10 02:20:51,040 - src.utils.metrics - INFO - Step 18, Epoch 0: {'policy_loss': -0.05745851178653538, 'reconstructor_loss': 3.561292886734009, 'total_loss': 3.5038344264030457, 'reward_mean': 0.0009664862272984465, 'compression_ratio': 0.6574137359857559, 'temperature': 0.99847, 'mask_ratio': 0.4125782400369644, 'policy_grad_norm': 0.003485984294457012, 'reconstructor_grad_norm': 0.7150893621146679}
INFO:src.utils.metrics:Step 18, Epoch 0: {'policy_loss': -0.05745851178653538, 'reconstructor_loss': 3.561292886734009, 'total_loss': 3.5038344264030457, 'reward_mean': 0.0009664862272984465, 'compression_ratio': 0.6574137359857559, 'temperature': 0.99847, 'mask_ratio': 0.4125782400369644, 'policy_grad_norm': 0.003485984294457012, 'reconstructor_grad_norm': 0.7150893621146679}
2025-08-10 02:20:58,492 - src.utils.metrics - INFO - Step 19, Epoch 0: {'policy_loss': -0.03225304710213095, 'reconstructor_loss': 3.6084123253822327, 'total_loss': 3.57615926861763, 'reward_mean': 0.0010688294637475337, 'compression_ratio': 0.6592264100909233, 'temperature': 0.9983799999999999, 'mask_ratio': 0.40794821456074715, 'policy_grad_norm': 0.0009341485601908062, 'reconstructor_grad_norm': 0.9390621837228537}
INFO:src.utils.metrics:Step 19, Epoch 0: {'policy_loss': -0.03225304710213095, 'reconstructor_loss': 3.6084123253822327, 'total_loss': 3.57615926861763, 'reward_mean': 0.0010688294637475337, 'compression_ratio': 0.6592264100909233, 'temperature': 0.9983799999999999, 'mask_ratio': 0.40794821456074715, 'policy_grad_norm': 0.0009341485601908062, 'reconstructor_grad_norm': 0.9390621837228537}
2025-08-10 02:21:10,282 - src.utils.metrics - INFO - Step 20, Epoch 0: {'policy_loss': -0.07771012134617195, 'reconstructor_loss': 3.8073984384536743, 'total_loss': 3.7296882569789886, 'reward_mean': 0.000946143670262245, 'compression_ratio': 0.63687664270401, 'temperature': 0.99829, 'mask_ratio': 0.43419045582413673, 'policy_grad_norm': 0.005361660678318003, 'reconstructor_grad_norm': 0.9029184430837631}
INFO:src.utils.metrics:Step 20, Epoch 0: {'policy_loss': -0.07771012134617195, 'reconstructor_loss': 3.8073984384536743, 'total_loss': 3.7296882569789886, 'reward_mean': 0.000946143670262245, 'compression_ratio': 0.63687664270401, 'temperature': 0.99829, 'mask_ratio': 0.43419045582413673, 'policy_grad_norm': 0.005361660678318003, 'reconstructor_grad_norm': 0.9029184430837631}
2025-08-10 02:21:20,816 - src.utils.metrics - INFO - Step 21, Epoch 0: {'policy_loss': -0.03884635312715545, 'reconstructor_loss': 3.7575334310531616, 'total_loss': 3.7186870872974396, 'reward_mean': 0.001112003681328133, 'compression_ratio': 0.6313427686691284, 'temperature': 0.9982, 'mask_ratio': 0.4510124437510967, 'policy_grad_norm': 0.0017290392042923486, 'reconstructor_grad_norm': 0.9248123280704021}
INFO:src.utils.metrics:Step 21, Epoch 0: {'policy_loss': -0.03884635312715545, 'reconstructor_loss': 3.7575334310531616, 'total_loss': 3.7186870872974396, 'reward_mean': 0.001112003681328133, 'compression_ratio': 0.6313427686691284, 'temperature': 0.9982, 'mask_ratio': 0.4510124437510967, 'policy_grad_norm': 0.0017290392042923486, 'reconstructor_grad_norm': 0.9248123280704021}
2025-08-10 02:21:33,179 - src.utils.metrics - INFO - Step 22, Epoch 0: {'policy_loss': -0.01708554261131212, 'reconstructor_loss': 3.8075035512447357, 'total_loss': 3.7904179990291595, 'reward_mean': 0.0006509044205813552, 'compression_ratio': 0.6285610124468803, 'temperature': 0.99811, 'mask_ratio': 0.4455864168703556, 'policy_grad_norm': 0.0003961271504522301, 'reconstructor_grad_norm': 0.7164769172668457}
INFO:src.utils.metrics:Step 22, Epoch 0: {'policy_loss': -0.01708554261131212, 'reconstructor_loss': 3.8075035512447357, 'total_loss': 3.7904179990291595, 'reward_mean': 0.0006509044205813552, 'compression_ratio': 0.6285610124468803, 'temperature': 0.99811, 'mask_ratio': 0.4455864168703556, 'policy_grad_norm': 0.0003961271504522301, 'reconstructor_grad_norm': 0.7164769172668457}
2025-08-10 02:21:47,146 - src.utils.metrics - INFO - Step 23, Epoch 0: {'policy_loss': -0.02367829595459625, 'reconstructor_loss': 3.8863400518894196, 'total_loss': 3.8626618087291718, 'reward_mean': 0.0005542766937196575, 'compression_ratio': 0.604850210249424, 'temperature': 0.99802, 'mask_ratio': 0.481801301240921, 'policy_grad_norm': 0.0004018280033051269, 'reconstructor_grad_norm': 0.8990275636315346}
INFO:src.utils.metrics:Step 23, Epoch 0: {'policy_loss': -0.02367829595459625, 'reconstructor_loss': 3.8863400518894196, 'total_loss': 3.8626618087291718, 'reward_mean': 0.0005542766937196575, 'compression_ratio': 0.604850210249424, 'temperature': 0.99802, 'mask_ratio': 0.481801301240921, 'policy_grad_norm': 0.0004018280033051269, 'reconstructor_grad_norm': 0.8990275636315346}
2025-08-10 02:21:59,298 - src.utils.metrics - INFO - Step 24, Epoch 0: {'policy_loss': -0.02329401852330193, 'reconstructor_loss': 3.92898166179657, 'total_loss': 3.9056876599788666, 'reward_mean': 0.0006526240449602483, 'compression_ratio': 0.6173502653837204, 'temperature': 0.99793, 'mask_ratio': 0.4597715139389038, 'policy_grad_norm': 0.0007526962463089149, 'reconstructor_grad_norm': 0.867235329002142}
INFO:src.utils.metrics:Step 24, Epoch 0: {'policy_loss': -0.02329401852330193, 'reconstructor_loss': 3.92898166179657, 'total_loss': 3.9056876599788666, 'reward_mean': 0.0006526240449602483, 'compression_ratio': 0.6173502653837204, 'temperature': 0.99793, 'mask_ratio': 0.4597715139389038, 'policy_grad_norm': 0.0007526962463089149, 'reconstructor_grad_norm': 0.867235329002142}
2025-08-10 02:22:12,328 - src.utils.metrics - INFO - Step 25, Epoch 0: {'policy_loss': -0.015322601364459842, 'reconstructor_loss': 3.8775142431259155, 'total_loss': 3.862191677093506, 'reward_mean': 0.000539986258445424, 'compression_ratio': 0.6339349001646042, 'temperature': 0.9978400000000001, 'mask_ratio': 0.4454941861331463, 'policy_grad_norm': 0.00036336382072477136, 'reconstructor_grad_norm': 0.8573079854249954}
INFO:src.utils.metrics:Step 25, Epoch 0: {'policy_loss': -0.015322601364459842, 'reconstructor_loss': 3.8775142431259155, 'total_loss': 3.862191677093506, 'reward_mean': 0.000539986258445424, 'compression_ratio': 0.6339349001646042, 'temperature': 0.9978400000000001, 'mask_ratio': 0.4454941861331463, 'policy_grad_norm': 0.00036336382072477136, 'reconstructor_grad_norm': 0.8573079854249954}
2025-08-10 02:22:22,561 - src.utils.metrics - INFO - Step 26, Epoch 0: {'policy_loss': -0.0748105111415498, 'reconstructor_loss': 3.5814785063266754, 'total_loss': 3.506667971611023, 'reward_mean': 0.001182789064841927, 'compression_ratio': 0.6492305174469948, 'temperature': 0.99775, 'mask_ratio': 0.4264950752258301, 'policy_grad_norm': 0.0017721860085657681, 'reconstructor_grad_norm': 1.0621857419610023}
INFO:src.utils.metrics:Step 26, Epoch 0: {'policy_loss': -0.0748105111415498, 'reconstructor_loss': 3.5814785063266754, 'total_loss': 3.506667971611023, 'reward_mean': 0.001182789064841927, 'compression_ratio': 0.6492305174469948, 'temperature': 0.99775, 'mask_ratio': 0.4264950752258301, 'policy_grad_norm': 0.0017721860085657681, 'reconstructor_grad_norm': 1.0621857419610023}
2025-08-10 02:22:31,892 - src.utils.metrics - INFO - Step 27, Epoch 0: {'policy_loss': -0.09944114059908316, 'reconstructor_loss': 3.9026210010051727, 'total_loss': 3.8031798899173737, 'reward_mean': 0.001235733179782983, 'compression_ratio': 0.6495955809950829, 'temperature': 0.99766, 'mask_ratio': 0.41991957277059555, 'policy_grad_norm': 0.0032105085101648, 'reconstructor_grad_norm': 0.9404199011623859}
INFO:src.utils.metrics:Step 27, Epoch 0: {'policy_loss': -0.09944114059908316, 'reconstructor_loss': 3.9026210010051727, 'total_loss': 3.8031798899173737, 'reward_mean': 0.001235733179782983, 'compression_ratio': 0.6495955809950829, 'temperature': 0.99766, 'mask_ratio': 0.41991957277059555, 'policy_grad_norm': 0.0032105085101648, 'reconstructor_grad_norm': 0.9404199011623859}
2025-08-10 02:22:42,027 - src.utils.metrics - INFO - Step 28, Epoch 0: {'policy_loss': -0.03257524664513767, 'reconstructor_loss': 3.618173509836197, 'total_loss': 3.585598260164261, 'reward_mean': 0.0006575614843313815, 'compression_ratio': 0.6584030538797379, 'temperature': 0.99757, 'mask_ratio': 0.4154122583568096, 'policy_grad_norm': 0.0007883748185122386, 'reconstructor_grad_norm': 0.7953118607401848}
INFO:src.utils.metrics:Step 28, Epoch 0: {'policy_loss': -0.03257524664513767, 'reconstructor_loss': 3.618173509836197, 'total_loss': 3.585598260164261, 'reward_mean': 0.0006575614843313815, 'compression_ratio': 0.6584030538797379, 'temperature': 0.99757, 'mask_ratio': 0.4154122583568096, 'policy_grad_norm': 0.0007883748185122386, 'reconstructor_grad_norm': 0.7953118607401848}
2025-08-10 02:22:55,715 - src.utils.metrics - INFO - Step 29, Epoch 0: {'policy_loss': -0.010073761804960668, 'reconstructor_loss': 3.8509755432605743, 'total_loss': 3.840901732444763, 'reward_mean': 0.0003506602533889236, 'compression_ratio': 0.6523555666208267, 'temperature': 0.9974799999999999, 'mask_ratio': 0.4274724908173084, 'policy_grad_norm': 0.0008289569777844008, 'reconstructor_grad_norm': 0.7826919183135033}
INFO:src.utils.metrics:Step 29, Epoch 0: {'policy_loss': -0.010073761804960668, 'reconstructor_loss': 3.8509755432605743, 'total_loss': 3.840901732444763, 'reward_mean': 0.0003506602533889236, 'compression_ratio': 0.6523555666208267, 'temperature': 0.9974799999999999, 'mask_ratio': 0.4274724908173084, 'policy_grad_norm': 0.0008289569777844008, 'reconstructor_grad_norm': 0.7826919183135033}
2025-08-10 02:23:10,732 - src.utils.metrics - INFO - Step 30, Epoch 0: {'policy_loss': -0.03155420668190345, 'reconstructor_loss': 3.5339375734329224, 'total_loss': 3.502383381128311, 'reward_mean': 0.0008283930665129446, 'compression_ratio': 0.6746781691908836, 'temperature': 0.99739, 'mask_ratio': 0.402860127389431, 'policy_grad_norm': 0.0019105549399682786, 'reconstructor_grad_norm': 0.5444019380956888}
INFO:src.utils.metrics:Step 30, Epoch 0: {'policy_loss': -0.03155420668190345, 'reconstructor_loss': 3.5339375734329224, 'total_loss': 3.502383381128311, 'reward_mean': 0.0008283930665129446, 'compression_ratio': 0.6746781691908836, 'temperature': 0.99739, 'mask_ratio': 0.402860127389431, 'policy_grad_norm': 0.0019105549399682786, 'reconstructor_grad_norm': 0.5444019380956888}
2025-08-10 02:23:25,109 - src.utils.metrics - INFO - Step 31, Epoch 0: {'policy_loss': -0.010721363651100546, 'reconstructor_loss': 3.9323684871196747, 'total_loss': 3.9216471314430237, 'reward_mean': 0.0003631728677646606, 'compression_ratio': 0.6538777351379395, 'temperature': 0.9973, 'mask_ratio': 0.4256651774048805, 'policy_grad_norm': 0.0016756135064497357, 'reconstructor_grad_norm': 0.7740971520543098}
INFO:src.utils.metrics:Step 31, Epoch 0: {'policy_loss': -0.010721363651100546, 'reconstructor_loss': 3.9323684871196747, 'total_loss': 3.9216471314430237, 'reward_mean': 0.0003631728677646606, 'compression_ratio': 0.6538777351379395, 'temperature': 0.9973, 'mask_ratio': 0.4256651774048805, 'policy_grad_norm': 0.0016756135064497357, 'reconstructor_grad_norm': 0.7740971520543098}
2025-08-10 02:23:36,662 - src.utils.metrics - INFO - Step 32, Epoch 0: {'policy_loss': -0.05424576619407162, 'reconstructor_loss': 3.7258377373218536, 'total_loss': 3.6715919971466064, 'reward_mean': 0.0014141156698315172, 'compression_ratio': 0.6760013476014137, 'temperature': 0.99721, 'mask_ratio': 0.3994177468121052, 'policy_grad_norm': 0.0036281131724535953, 'reconstructor_grad_norm': 0.5741448123008013}
INFO:src.utils.metrics:Step 32, Epoch 0: {'policy_loss': -0.05424576619407162, 'reconstructor_loss': 3.7258377373218536, 'total_loss': 3.6715919971466064, 'reward_mean': 0.0014141156698315172, 'compression_ratio': 0.6760013476014137, 'temperature': 0.99721, 'mask_ratio': 0.3994177468121052, 'policy_grad_norm': 0.0036281131724535953, 'reconstructor_grad_norm': 0.5741448123008013}
2025-08-10 02:23:50,352 - src.utils.metrics - INFO - Step 33, Epoch 0: {'policy_loss': -0.019955967203713953, 'reconstructor_loss': 3.9282398521900177, 'total_loss': 3.9082838594913483, 'reward_mean': 0.00040552541531724273, 'compression_ratio': 0.6690479889512062, 'temperature': 0.99712, 'mask_ratio': 0.41583386063575745, 'policy_grad_norm': 0.002865023645426845, 'reconstructor_grad_norm': 0.7437950894236565}
INFO:src.utils.metrics:Step 33, Epoch 0: {'policy_loss': -0.019955967203713953, 'reconstructor_loss': 3.9282398521900177, 'total_loss': 3.9082838594913483, 'reward_mean': 0.00040552541531724273, 'compression_ratio': 0.6690479889512062, 'temperature': 0.99712, 'mask_ratio': 0.41583386063575745, 'policy_grad_norm': 0.002865023645426845, 'reconstructor_grad_norm': 0.7437950894236565}
2025-08-10 02:24:04,156 - src.utils.metrics - INFO - Step 34, Epoch 0: {'policy_loss': -0.03130288689862937, 'reconstructor_loss': 4.140519708395004, 'total_loss': 4.1092168390750885, 'reward_mean': 0.00048488150650882744, 'compression_ratio': 0.6568926572799683, 'temperature': 0.9970300000000001, 'mask_ratio': 0.42321936413645744, 'policy_grad_norm': 0.004007219980849186, 'reconstructor_grad_norm': 0.7725182846188545}
INFO:src.utils.metrics:Step 34, Epoch 0: {'policy_loss': -0.03130288689862937, 'reconstructor_loss': 4.140519708395004, 'total_loss': 4.1092168390750885, 'reward_mean': 0.00048488150650882744, 'compression_ratio': 0.6568926572799683, 'temperature': 0.9970300000000001, 'mask_ratio': 0.42321936413645744, 'policy_grad_norm': 0.004007219980849186, 'reconstructor_grad_norm': 0.7725182846188545}
2025-08-10 02:24:12,041 - src.utils.metrics - INFO - Step 35, Epoch 0: {'policy_loss': -0.017402584955561906, 'reconstructor_loss': 4.055045425891876, 'total_loss': 4.037642806768417, 'reward_mean': 0.0003139108321192907, 'compression_ratio': 0.6611756980419159, 'temperature': 0.99694, 'mask_ratio': 0.4253067933022976, 'policy_grad_norm': 0.0029352771016419865, 'reconstructor_grad_norm': 0.8644418530166149}
INFO:src.utils.metrics:Step 35, Epoch 0: {'policy_loss': -0.017402584955561906, 'reconstructor_loss': 4.055045425891876, 'total_loss': 4.037642806768417, 'reward_mean': 0.0003139108321192907, 'compression_ratio': 0.6611756980419159, 'temperature': 0.99694, 'mask_ratio': 0.4253067933022976, 'policy_grad_norm': 0.0029352771016419865, 'reconstructor_grad_norm': 0.8644418530166149}
2025-08-10 02:24:28,202 - src.utils.metrics - INFO - Step 36, Epoch 0: {'policy_loss': -0.030726148514077067, 'reconstructor_loss': 3.913106232881546, 'total_loss': 3.882380038499832, 'reward_mean': 0.0007488418342518344, 'compression_ratio': 0.670114554464817, 'temperature': 0.99685, 'mask_ratio': 0.40904073789715767, 'policy_grad_norm': 0.0033215854200534523, 'reconstructor_grad_norm': 0.6623675990849733}
INFO:src.utils.metrics:Step 36, Epoch 0: {'policy_loss': -0.030726148514077067, 'reconstructor_loss': 3.913106232881546, 'total_loss': 3.882380038499832, 'reward_mean': 0.0007488418342518344, 'compression_ratio': 0.670114554464817, 'temperature': 0.99685, 'mask_ratio': 0.40904073789715767, 'policy_grad_norm': 0.0033215854200534523, 'reconstructor_grad_norm': 0.6623675990849733}
2025-08-10 02:24:43,832 - src.utils.metrics - INFO - Step 37, Epoch 0: {'policy_loss': -0.02728014561580494, 'reconstructor_loss': 4.049809396266937, 'total_loss': 4.022529244422913, 'reward_mean': 0.0005043181929522689, 'compression_ratio': 0.6543133705854416, 'temperature': 0.99676, 'mask_ratio': 0.43011749908328056, 'policy_grad_norm': 0.0024672399395058164, 'reconstructor_grad_norm': 0.9395450875163078}
INFO:src.utils.metrics:Step 37, Epoch 0: {'policy_loss': -0.02728014561580494, 'reconstructor_loss': 4.049809396266937, 'total_loss': 4.022529244422913, 'reward_mean': 0.0005043181929522689, 'compression_ratio': 0.6543133705854416, 'temperature': 0.99676, 'mask_ratio': 0.43011749908328056, 'policy_grad_norm': 0.0024672399395058164, 'reconstructor_grad_norm': 0.9395450875163078}
2025-08-10 02:25:01,610 - src.utils.metrics - INFO - Step 38, Epoch 0: {'policy_loss': -0.04706666339188814, 'reconstructor_loss': 3.7257201075553894, 'total_loss': 3.6786534786224365, 'reward_mean': 0.0009238970765181875, 'compression_ratio': 0.6764179244637489, 'temperature': 0.99667, 'mask_ratio': 0.40145590156316757, 'policy_grad_norm': 0.0019001417840627255, 'reconstructor_grad_norm': 0.6842732820659876}
INFO:src.utils.metrics:Step 38, Epoch 0: {'policy_loss': -0.04706666339188814, 'reconstructor_loss': 3.7257201075553894, 'total_loss': 3.6786534786224365, 'reward_mean': 0.0009238970765181875, 'compression_ratio': 0.6764179244637489, 'temperature': 0.99667, 'mask_ratio': 0.40145590156316757, 'policy_grad_norm': 0.0019001417840627255, 'reconstructor_grad_norm': 0.6842732820659876}
2025-08-10 02:25:07,308 - src.utils.metrics - INFO - Step 39, Epoch 0: {'policy_loss': -0.016990133794024587, 'reconstructor_loss': 4.2147350907325745, 'total_loss': 4.197744935750961, 'reward_mean': 0.0004085984485300287, 'compression_ratio': 0.6436278522014618, 'temperature': 0.99658, 'mask_ratio': 0.4356607124209404, 'policy_grad_norm': 0.000845881387249392, 'reconstructor_grad_norm': 0.9344320967793465}
INFO:src.utils.metrics:Step 39, Epoch 0: {'policy_loss': -0.016990133794024587, 'reconstructor_loss': 4.2147350907325745, 'total_loss': 4.197744935750961, 'reward_mean': 0.0004085984485300287, 'compression_ratio': 0.6436278522014618, 'temperature': 0.99658, 'mask_ratio': 0.4356607124209404, 'policy_grad_norm': 0.000845881387249392, 'reconstructor_grad_norm': 0.9344320967793465}
2025-08-10 02:25:23,588 - src.utils.metrics - INFO - Step 40, Epoch 0: {'policy_loss': -0.024206527625210583, 'reconstructor_loss': 3.6654607951641083, 'total_loss': 3.6412543058395386, 'reward_mean': 0.000712764291165513, 'compression_ratio': 0.6599246934056282, 'temperature': 0.99649, 'mask_ratio': 0.4181799404323101, 'policy_grad_norm': 0.0008202955286833458, 'reconstructor_grad_norm': 0.8979188166558743}
INFO:src.utils.metrics:Step 40, Epoch 0: {'policy_loss': -0.024206527625210583, 'reconstructor_loss': 3.6654607951641083, 'total_loss': 3.6412543058395386, 'reward_mean': 0.000712764291165513, 'compression_ratio': 0.6599246934056282, 'temperature': 0.99649, 'mask_ratio': 0.4181799404323101, 'policy_grad_norm': 0.0008202955286833458, 'reconstructor_grad_norm': 0.8979188166558743}
2025-08-10 02:25:34,964 - src.utils.metrics - INFO - Step 41, Epoch 0: {'policy_loss': -0.04823975433828309, 'reconstructor_loss': 3.7174016535282135, 'total_loss': 3.6691618859767914, 'reward_mean': 0.0009208029503042781, 'compression_ratio': 0.6707674488425255, 'temperature': 0.9964, 'mask_ratio': 0.4069482795894146, 'policy_grad_norm': 0.0005989027577015804, 'reconstructor_grad_norm': 0.7573277726769447}
INFO:src.utils.metrics:Step 41, Epoch 0: {'policy_loss': -0.04823975433828309, 'reconstructor_loss': 3.7174016535282135, 'total_loss': 3.6691618859767914, 'reward_mean': 0.0009208029503042781, 'compression_ratio': 0.6707674488425255, 'temperature': 0.9964, 'mask_ratio': 0.4069482795894146, 'policy_grad_norm': 0.0005989027577015804, 'reconstructor_grad_norm': 0.7573277726769447}
2025-08-10 02:25:58,838 - src.utils.metrics - INFO - Step 42, Epoch 0: {'policy_loss': -0.07345630665076897, 'reconstructor_loss': 3.72867688536644, 'total_loss': 3.655220627784729, 'reward_mean': 0.001268148405415559, 'compression_ratio': 0.6469047293066978, 'temperature': 0.99631, 'mask_ratio': 0.4332394003868103, 'policy_grad_norm': 0.0008566877822886454, 'reconstructor_grad_norm': 0.9298571459949017}
INFO:src.utils.metrics:Step 42, Epoch 0: {'policy_loss': -0.07345630665076897, 'reconstructor_loss': 3.72867688536644, 'total_loss': 3.655220627784729, 'reward_mean': 0.001268148405415559, 'compression_ratio': 0.6469047293066978, 'temperature': 0.99631, 'mask_ratio': 0.4332394003868103, 'policy_grad_norm': 0.0008566877822886454, 'reconstructor_grad_norm': 0.9298571459949017}
2025-08-10 02:26:19,804 - src.utils.metrics - INFO - Step 43, Epoch 0: {'policy_loss': -0.07056562410434708, 'reconstructor_loss': 3.3496410250663757, 'total_loss': 3.2790753841400146, 'reward_mean': 0.0014682116543554002, 'compression_ratio': 0.6756615117192268, 'temperature': 0.99622, 'mask_ratio': 0.3953304775059223, 'policy_grad_norm': 0.001160458879894577, 'reconstructor_grad_norm': 0.5629157421644777}
INFO:src.utils.metrics:Step 43, Epoch 0: {'policy_loss': -0.07056562410434708, 'reconstructor_loss': 3.3496410250663757, 'total_loss': 3.2790753841400146, 'reward_mean': 0.0014682116543554002, 'compression_ratio': 0.6756615117192268, 'temperature': 0.99622, 'mask_ratio': 0.3953304775059223, 'policy_grad_norm': 0.001160458879894577, 'reconstructor_grad_norm': 0.5629157421644777}
2025-08-10 02:26:33,023 - src.utils.metrics - INFO - Step 44, Epoch 0: {'policy_loss': -0.03452870954060927, 'reconstructor_loss': 3.8430581986904144, 'total_loss': 3.8085294663906097, 'reward_mean': 0.0006957502864679554, 'compression_ratio': 0.6315978318452835, 'temperature': 0.9961300000000001, 'mask_ratio': 0.4438525587320328, 'policy_grad_norm': 0.0006021824501658557, 'reconstructor_grad_norm': 0.8641012236475945}
INFO:src.utils.metrics:Step 44, Epoch 0: {'policy_loss': -0.03452870954060927, 'reconstructor_loss': 3.8430581986904144, 'total_loss': 3.8085294663906097, 'reward_mean': 0.0006957502864679554, 'compression_ratio': 0.6315978318452835, 'temperature': 0.9961300000000001, 'mask_ratio': 0.4438525587320328, 'policy_grad_norm': 0.0006021824501658557, 'reconstructor_grad_norm': 0.8641012236475945}
2025-08-10 02:26:43,712 - src.utils.metrics - INFO - Step 45, Epoch 0: {'policy_loss': -0.021619407460093498, 'reconstructor_loss': 3.7603327929973602, 'total_loss': 3.738713353872299, 'reward_mean': 0.0006186408882058458, 'compression_ratio': 0.6334013789892197, 'temperature': 0.99604, 'mask_ratio': 0.4459860436618328, 'policy_grad_norm': 0.0006517927386084921, 'reconstructor_grad_norm': 0.7907651197165251}
INFO:src.utils.metrics:Step 45, Epoch 0: {'policy_loss': -0.021619407460093498, 'reconstructor_loss': 3.7603327929973602, 'total_loss': 3.738713353872299, 'reward_mean': 0.0006186408882058458, 'compression_ratio': 0.6334013789892197, 'temperature': 0.99604, 'mask_ratio': 0.4459860436618328, 'policy_grad_norm': 0.0006517927386084921, 'reconstructor_grad_norm': 0.7907651197165251}
2025-08-10 02:26:56,441 - src.utils.metrics - INFO - Step 46, Epoch 0: {'policy_loss': -0.01859356032218784, 'reconstructor_loss': 3.677104026079178, 'total_loss': 3.6585104763507843, 'reward_mean': 0.0005563342492678203, 'compression_ratio': 0.6491092219948769, 'temperature': 0.99595, 'mask_ratio': 0.4230111390352249, 'policy_grad_norm': 0.00026956166584568564, 'reconstructor_grad_norm': 0.7298825830221176}
INFO:src.utils.metrics:Step 46, Epoch 0: {'policy_loss': -0.01859356032218784, 'reconstructor_loss': 3.677104026079178, 'total_loss': 3.6585104763507843, 'reward_mean': 0.0005563342492678203, 'compression_ratio': 0.6491092219948769, 'temperature': 0.99595, 'mask_ratio': 0.4230111390352249, 'policy_grad_norm': 0.00026956166584568564, 'reconstructor_grad_norm': 0.7298825830221176}
2025-08-10 02:27:12,207 - src.utils.metrics - INFO - Step 47, Epoch 0: {'policy_loss': -0.03763239673571661, 'reconstructor_loss': 3.9567470848560333, 'total_loss': 3.9191146194934845, 'reward_mean': 0.0006246189377634437, 'compression_ratio': 0.6225846707820892, 'temperature': 0.99586, 'mask_ratio': 0.458106841892004, 'policy_grad_norm': 0.0003725100013980409, 'reconstructor_grad_norm': 0.7544651934877038}
INFO:src.utils.metrics:Step 47, Epoch 0: {'policy_loss': -0.03763239673571661, 'reconstructor_loss': 3.9567470848560333, 'total_loss': 3.9191146194934845, 'reward_mean': 0.0006246189377634437, 'compression_ratio': 0.6225846707820892, 'temperature': 0.99586, 'mask_ratio': 0.458106841892004, 'policy_grad_norm': 0.0003725100013980409, 'reconstructor_grad_norm': 0.7544651934877038}
2025-08-10 02:27:27,625 - src.utils.metrics - INFO - Step 48, Epoch 0: {'policy_loss': -0.07272905227728188, 'reconstructor_loss': 3.9627614617347717, 'total_loss': 3.8900324255228043, 'reward_mean': 0.0009605494462903152, 'compression_ratio': 0.6082614362239838, 'temperature': 0.9957699999999999, 'mask_ratio': 0.4747703745961189, 'policy_grad_norm': 0.005606792542948824, 'reconstructor_grad_norm': 0.7539508864283562}
INFO:src.utils.metrics:Step 48, Epoch 0: {'policy_loss': -0.07272905227728188, 'reconstructor_loss': 3.9627614617347717, 'total_loss': 3.8900324255228043, 'reward_mean': 0.0009605494462903152, 'compression_ratio': 0.6082614362239838, 'temperature': 0.9957699999999999, 'mask_ratio': 0.4747703745961189, 'policy_grad_norm': 0.005606792542948824, 'reconstructor_grad_norm': 0.7539508864283562}
2025-08-10 02:27:41,574 - src.utils.metrics - INFO - Step 49, Epoch 0: {'policy_loss': -0.04487473954213783, 'reconstructor_loss': 3.719402104616165, 'total_loss': 3.6745274364948273, 'reward_mean': 0.0010309945682820398, 'compression_ratio': 0.6408030912280083, 'temperature': 0.99568, 'mask_ratio': 0.43515269458293915, 'policy_grad_norm': 0.0023976201700861566, 'reconstructor_grad_norm': 0.573078982764855}
INFO:src.utils.metrics:Step 49, Epoch 0: {'policy_loss': -0.04487473954213783, 'reconstructor_loss': 3.719402104616165, 'total_loss': 3.6745274364948273, 'reward_mean': 0.0010309945682820398, 'compression_ratio': 0.6408030912280083, 'temperature': 0.99568, 'mask_ratio': 0.43515269458293915, 'policy_grad_norm': 0.0023976201700861566, 'reconstructor_grad_norm': 0.573078982764855}
2025-08-10 02:28:01,895 - src.utils.metrics - INFO - Step 50, Epoch 0: {'policy_loss': -0.07405295770149678, 'reconstructor_loss': 3.206931382417679, 'total_loss': 3.1328784227371216, 'reward_mean': 0.0013387351427809335, 'compression_ratio': 0.6829031109809875, 'temperature': 0.99559, 'mask_ratio': 0.3838478624820709, 'policy_grad_norm': 0.0021306985545379575, 'reconstructor_grad_norm': 0.2688170177862048}
INFO:src.utils.metrics:Step 50, Epoch 0: {'policy_loss': -0.07405295770149678, 'reconstructor_loss': 3.206931382417679, 'total_loss': 3.1328784227371216, 'reward_mean': 0.0013387351427809335, 'compression_ratio': 0.6829031109809875, 'temperature': 0.99559, 'mask_ratio': 0.3838478624820709, 'policy_grad_norm': 0.0021306985545379575, 'reconstructor_grad_norm': 0.2688170177862048}
2025-08-10 02:28:02,333 - src.training.trainer - INFO - Step 50 - policy_loss: -0.0496, reconstructor_loss: 3.6922, total_loss: 3.6426, reward_mean: 0.0009, compression_ratio: 0.6462, temperature: 0.9960, mask_ratio: 0.4300, policy_grad_norm: 0.0015, reconstructor_grad_norm: 0.6985 | Unified Memory: 33.5GB (69.7% pressure)
INFO:src.training.trainer:Step 50 - policy_loss: -0.0496, reconstructor_loss: 3.6922, total_loss: 3.6426, reward_mean: 0.0009, compression_ratio: 0.6462, temperature: 0.9960, mask_ratio: 0.4300, policy_grad_norm: 0.0015, reconstructor_grad_norm: 0.6985 | Unified Memory: 33.5GB (69.7% pressure)
2025-08-10 02:28:10,283 - src.utils.metrics - INFO - Step 51, Epoch 0: {'policy_loss': -0.031920999696012586, 'reconstructor_loss': 3.7177659571170807, 'total_loss': 3.685844987630844, 'reward_mean': 0.0008073462913671392, 'compression_ratio': 0.6360250487923622, 'temperature': 0.9954999999999999, 'mask_ratio': 0.4400613605976105, 'policy_grad_norm': 0.001294084097025916, 'reconstructor_grad_norm': 0.7135028056800365}
INFO:src.utils.metrics:Step 51, Epoch 0: {'policy_loss': -0.031920999696012586, 'reconstructor_loss': 3.7177659571170807, 'total_loss': 3.685844987630844, 'reward_mean': 0.0008073462913671392, 'compression_ratio': 0.6360250487923622, 'temperature': 0.9954999999999999, 'mask_ratio': 0.4400613605976105, 'policy_grad_norm': 0.001294084097025916, 'reconstructor_grad_norm': 0.7135028056800365}
2025-08-10 02:28:21,305 - src.utils.metrics - INFO - Step 52, Epoch 0: {'policy_loss': -0.011475043778773397, 'reconstructor_loss': 3.9167120456695557, 'total_loss': 3.9052369594573975, 'reward_mean': 0.0003035339977941476, 'compression_ratio': 0.6086678728461266, 'temperature': 0.99541, 'mask_ratio': 0.4741600602865219, 'policy_grad_norm': 0.00035325047610967886, 'reconstructor_grad_norm': 0.9235232770442963}
INFO:src.utils.metrics:Step 52, Epoch 0: {'policy_loss': -0.011475043778773397, 'reconstructor_loss': 3.9167120456695557, 'total_loss': 3.9052369594573975, 'reward_mean': 0.0003035339977941476, 'compression_ratio': 0.6086678728461266, 'temperature': 0.99541, 'mask_ratio': 0.4741600602865219, 'policy_grad_norm': 0.00035325047610967886, 'reconstructor_grad_norm': 0.9235232770442963}
2025-08-10 02:28:38,328 - src.utils.metrics - INFO - Step 53, Epoch 0: {'policy_loss': -0.04353879386326298, 'reconstructor_loss': 3.7460165917873383, 'total_loss': 3.702477842569351, 'reward_mean': 0.0009285345024636626, 'compression_ratio': 0.637768104672432, 'temperature': 0.99532, 'mask_ratio': 0.43950002640485764, 'policy_grad_norm': 0.0009379648545291275, 'reconstructor_grad_norm': 0.7347024865448475}
INFO:src.utils.metrics:Step 53, Epoch 0: {'policy_loss': -0.04353879386326298, 'reconstructor_loss': 3.7460165917873383, 'total_loss': 3.702477842569351, 'reward_mean': 0.0009285345024636626, 'compression_ratio': 0.637768104672432, 'temperature': 0.99532, 'mask_ratio': 0.43950002640485764, 'policy_grad_norm': 0.0009379648545291275, 'reconstructor_grad_norm': 0.7347024865448475}
2025-08-10 02:28:58,113 - src.utils.metrics - INFO - Step 54, Epoch 0: {'policy_loss': -0.07790869515156373, 'reconstructor_loss': 3.4816247820854187, 'total_loss': 3.4037160873413086, 'reward_mean': 0.001279648319723492, 'compression_ratio': 0.6678266748785973, 'temperature': 0.9952300000000001, 'mask_ratio': 0.4030008427798748, 'policy_grad_norm': 0.002104737191075401, 'reconstructor_grad_norm': 0.7839333768934011}
INFO:src.utils.metrics:Step 54, Epoch 0: {'policy_loss': -0.07790869515156373, 'reconstructor_loss': 3.4816247820854187, 'total_loss': 3.4037160873413086, 'reward_mean': 0.001279648319723492, 'compression_ratio': 0.6678266748785973, 'temperature': 0.9952300000000001, 'mask_ratio': 0.4030008427798748, 'policy_grad_norm': 0.002104737191075401, 'reconstructor_grad_norm': 0.7839333768934011}
2025-08-10 02:29:19,336 - src.utils.metrics - INFO - Step 55, Epoch 0: {'policy_loss': -0.019403826561756432, 'reconstructor_loss': 3.814671367406845, 'total_loss': 3.795267552137375, 'reward_mean': 0.000490225165776792, 'compression_ratio': 0.6301458477973938, 'temperature': 0.99514, 'mask_ratio': 0.4480888992547989, 'policy_grad_norm': 0.00041716928990354063, 'reconstructor_grad_norm': 0.6779152397066355}
INFO:src.utils.metrics:Step 55, Epoch 0: {'policy_loss': -0.019403826561756432, 'reconstructor_loss': 3.814671367406845, 'total_loss': 3.795267552137375, 'reward_mean': 0.000490225165776792, 'compression_ratio': 0.6301458477973938, 'temperature': 0.99514, 'mask_ratio': 0.4480888992547989, 'policy_grad_norm': 0.00041716928990354063, 'reconstructor_grad_norm': 0.6779152397066355}
2025-08-10 02:29:39,926 - src.training.trainer - INFO - Training interrupted by user - Step 55 (Epoch 0)
INFO:src.training.trainer:Training interrupted by user - Step 55 (Epoch 0)
2025-08-10 02:29:41,361 - src.utils.logging - ERROR - Experiment joint_training failed: 
ERROR:src.utils.logging:Experiment joint_training failed: 

Interrupted by user
